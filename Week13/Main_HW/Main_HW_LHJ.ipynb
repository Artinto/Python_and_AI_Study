{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_HW_LHJ.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnonoPyhE-8d"
      },
      "source": [
        "# 실습 3: Custom 데이터로 CNN 실습\n",
        "## 1. 필요한 모듈 선언하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgWsx2eBEuGD"
      },
      "source": [
        "import torch\n",
        "import torch.cuda as cuda\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.transforms import RandomCrop, Resize, Compose, ToTensor, Normalize\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqleN0LhF4Qk"
      },
      "source": [
        "## 2. Device 및 seed 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBfx5CznF9sd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e734aa3-0c71-4f7d-c474-bf7e33902f60"
      },
      "source": [
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "if device=='cuda':\n",
        "    torch.cuda.manual_seed_all(1)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFkGEXA2GL0j"
      },
      "source": [
        "## 3. 데이터셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY-5p-LXLkNq"
      },
      "source": [
        "class mydataset(Dataset):\n",
        "    def __init__(self, path, transfer):\n",
        "        data = ImageFolder(root=path, transform=transfer)\n",
        "        self.imgs = []\n",
        "        self.labels = []\n",
        "\n",
        "        for i, (img, label) in enumerate(data):\n",
        "            self.imgs.append(img)\n",
        "            self.labels.append([label])\n",
        "\n",
        "        self.length = len(self.labels)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        data = self.imgs[item]\n",
        "        target = torch.Tensor(self.labels[item]).to(torch.long).squeeze()\n",
        "        return data, target\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYGCn5HLGQHN"
      },
      "source": [
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "transferF = Compose([Resize([256, 256]), RandomCrop([224, 224]), ToTensor(), normalize])\n",
        "transferFte = Compose([Resize([224, 224]), ToTensor(), normalize])\n",
        "\n",
        "train_dataset = mydataset('./drive/MyDrive/custom_dataset/train/', transferF)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=100,\n",
        "                                           shuffle=True,)\n",
        "\n",
        "test_dataset = mydataset('./drive/MyDrive/custom_dataset/test/', transferFte)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=100,\n",
        "                                           shuffle=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy7h4bIJFcOH"
      },
      "source": [
        "## 4. 모델 선언"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE1tXOQCFff3"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.imagesize = (224,224,3)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 10, kernel_size=5, padding=2)     #out 10,224,224\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5, padding=2)    #out 20,224,224\n",
        "        self.mp1 = nn.MaxPool2d(2)                                   #out 20,112,112\n",
        "\n",
        "        self.conv3 = nn.Conv2d(20, 20, kernel_size=3, padding=1)  # out 20,112,112\n",
        "        self.conv4 = nn.Conv2d(20, 20, kernel_size=3, padding=1)  # out 20,112,112\n",
        "        self.mp2 = nn.MaxPool2d(2)  # out 20,56,56\n",
        "\n",
        "        self.fc1 = nn.Linear(20 * 56 * 56, 512)\n",
        "        self.fc2 = nn.Linear(512, 4)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        in_size = x.size(0)\n",
        "\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.mp1(self.conv2(x)))\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.mp2(self.conv4(x)))\n",
        "\n",
        "        x = x.view(in_size, -1)  # flatten the tensor\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)             # batch, 4\n",
        "\n",
        "        return x\n",
        "\n",
        "model = Net()\n",
        "model = model.to(device)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO2nnyNNGFxv"
      },
      "source": [
        "## 5. 학습 시작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkTsKs7BGKZl",
        "outputId": "4231d8d7-cda4-4e15-b7e5-9f013e9e3145"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "Best = -1\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        train_loss += loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += criterion(output, target).item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    if acc > Best:\n",
        "        Best = acc\n",
        "        \n",
        "    print('\\nTrain set {} Epoch: loss: {:.4f}'.format(epoch, loss))\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Best Accuracy {:.0f}%\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset), acc, Best))\n",
        "    print('=='*100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train set 1 Epoch: loss: 1.2303\n",
            "\n",
            "Test set: Average loss: 1.2535, Accuracy: 47/100 (47%), Best Accuracy 47%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 2 Epoch: loss: 0.6978\n",
            "\n",
            "Test set: Average loss: 0.7540, Accuracy: 65/100 (65%), Best Accuracy 65%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 3 Epoch: loss: 0.5322\n",
            "\n",
            "Test set: Average loss: 0.5071, Accuracy: 84/100 (84%), Best Accuracy 84%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 4 Epoch: loss: 0.4476\n",
            "\n",
            "Test set: Average loss: 0.4469, Accuracy: 83/100 (83%), Best Accuracy 84%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 5 Epoch: loss: 0.2321\n",
            "\n",
            "Test set: Average loss: 0.3138, Accuracy: 91/100 (91%), Best Accuracy 91%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 6 Epoch: loss: 0.1175\n",
            "\n",
            "Test set: Average loss: 0.3183, Accuracy: 88/100 (88%), Best Accuracy 91%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 7 Epoch: loss: 0.2899\n",
            "\n",
            "Test set: Average loss: 0.2524, Accuracy: 93/100 (93%), Best Accuracy 93%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 8 Epoch: loss: 0.1391\n",
            "\n",
            "Test set: Average loss: 0.3288, Accuracy: 95/100 (95%), Best Accuracy 95%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 9 Epoch: loss: 0.0359\n",
            "\n",
            "Test set: Average loss: 0.4740, Accuracy: 82/100 (82%), Best Accuracy 95%\n",
            "\n",
            "========================================================================================================================================================================================================\n",
            "\n",
            "Train set 10 Epoch: loss: 0.0431\n",
            "\n",
            "Test set: Average loss: 0.4931, Accuracy: 84/100 (84%), Best Accuracy 95%\n",
            "\n",
            "========================================================================================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}