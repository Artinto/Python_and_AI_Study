{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load\n",
    "\n",
    "## 1. 실습을 위해 torch 의 도구들 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader # Dataset, DataLoader import\n",
    "# Dataset : custom dataset 에서 Dataset class 안에 있는 __getitem__() 과 __len__() 수정하여 사용하기 위함\n",
    "# DataLoader : mini batch 단위로 데이터들을 iterable 하게 쪼개고 각 batch를 무작위로 섞게 해주는 class\n",
    "from torch import from_numpy, tensor \n",
    "# from_numpy : numpy.ndarray(N차원의 배열 객체로, 같은 type 의 데이터로 구성) 로부터 Tensor 생성하도록 해주는 모듈\n",
    "# tensor : Tensor 생성하도록 해주는 모듈\n",
    "import numpy as np\n",
    "# numpy : np.loadtxt 를 사용하기 위해 import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 선언\n",
    "### Dataset 의 subclass 인 custom dataset 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset): # Dataset 의 subclass\n",
    "    \"\"\" Diabetes dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):\n",
    "        xy = np.loadtxt('./data/diabetes.csv.gz',\n",
    "                        delimiter=',', dtype=np.float32) \n",
    "        # xy : csv 파일의 데이터를 float type array 로 저장\n",
    "        # delimiter : csv가 콤마(,)로 행,열을 구분하므로 각 데이터를 delimiter=',' 로  쪼개준다.\n",
    "        # dtype=float32 : 데이터들을 float32 로 형변환해준다\n",
    "\n",
    "        self.len = xy.shape[0] # len : xy의 행 개수\n",
    "        self.x_data = from_numpy(xy[:, 0:-1])  # 첫번째 :->  행 전체 선택, 두번째 :-> 전체에서 가장 우측 열 제외한 나머지 선택\n",
    "        self.y_data = from_numpy(xy[:, [-1]]) # 첫번째 :->  행 전체 선택, [-1] -> 가장 우측 열만 선택\n",
    "\n",
    "    def __getitem__(self, index): # 인덱스를 받음\n",
    "        return self.x_data[index], self.y_data[index] # __getitem__ : 주어진 index 에 맞는 item 을 반환\n",
    "\n",
    "    def __len__(self): # object의 행 개수 \n",
    "        return self.len # 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. custom dataset 의 instance 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DiabetesDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. train_loader 에 DataLoader 사용하여 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset, # DataLoader 는 기본적으로 2개의 인자(데이터셋, 미니 배치의 크기)를 입력받음\n",
    "                          batch_size=32,   # 미니 배치의 크기는 보통 2의 배수를 사용 ( default : batch_size = 1 )\n",
    "                          shuffle=True,    # 추가적으로 shuffle 인자 사용 (default : shuffle = False)\n",
    "                                                            # -> shuffle=True 하면 데이터 학습 순서 무작위\n",
    "                                                            # < shuffle=True 사용 이유 >\n",
    "                                                            # 매 epoch 마다 똑같은 순서로 학습하면 \n",
    "                                                            # dataset 내용물 보다 dataset의 순서를 학습하여 바람직하지 않음\n",
    "                          num_workers=2)    # num_workers : multiple processes 를 필요로 할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "     # train_loader 는 iterable 하므로 for문을 돌릴 수 있다. == 미니 배치를 차례로 data에 저장가능하다\n",
    "    for i, data in enumerate(train_loader, 0): # i : batch의 index 저장, data : train_loader가 가져온 미니 배치 저장\n",
    "        # get the inputs\n",
    "        inputs, labels = data # mini batch 들을 inputs 과 labels 로 나눈다\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = tensor(inputs), tensor(labels) \n",
    "\n",
    "        # Run your training process\n",
    "        print(f'Epoch: {i} | Inputs {inputs.data} | Labels {labels.data}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
